"""
Script to compare predictions from Python ONNX Runtime and C ONNX Runtime.
Reads CSV files generated by both implementations and verifies they match.
"""

import csv
import sys
from typing import List, Tuple


def read_predictions_csv(filepath: str) -> List[Tuple[int, int, int, float]]:
    """Read predictions from CSV file.

    Returns list of tuples: (index, prediction, label, top_logit)
    """
    predictions = []
    with open(filepath, "r") as f:
        reader = csv.DictReader(f)
        for row in reader:
            predictions.append(
                (
                    int(row["index"]),
                    int(row["prediction"]),
                    int(row["label"]),
                    float(row["top_logit"]),
                )
            )
    return predictions


def compare_predictions(
    python_csv: str = "python_predictions.csv", c_csv: str = "c_predictions.csv"
) -> None:
    """Compare predictions from Python and C implementations."""

    print(f"Reading Python predictions from {python_csv}...")
    python_preds = read_predictions_csv(python_csv)

    print(f"Reading C predictions from {c_csv}...")
    c_preds = read_predictions_csv(c_csv)

    if len(python_preds) != len(c_preds):
        print(f"ERROR: Different number of predictions!")
        print(f"  Python: {len(python_preds)} samples")
        print(f"  C:      {len(c_preds)} samples")
        sys.exit(1)

    total = len(python_preds)
    mismatches = 0
    mismatch_details = []

    # tolerance for logit comparison
    tol = 1e-6

    for py_row, c_row in zip(python_preds, c_preds):
        py_idx, py_pred, py_label, py_logit = py_row
        c_idx, c_pred, c_label, c_logit = c_row

        if py_idx != c_idx:
            print(f"ERROR: Index mismatch at position (Python: {py_idx}, C: {c_idx})")
            sys.exit(1)

        if py_label != c_label:
            print(
                f"ERROR: Label mismatch at index {py_idx} (Python: {py_label}, C: {c_label})"
            )
            sys.exit(1)

        if py_pred != c_pred:
            mismatches += 1
            if len(mismatch_details) < 20:
                mismatch_details.append(
                    {
                        "index": py_idx,
                        "python_pred": py_pred,
                        "c_pred": c_pred,
                        "python_logit": py_logit,
                        "c_logit": c_logit,
                        "label": py_label,
                    }
                )
        else:
            # predictions agree; check top_logit numerical closeness
            if abs(py_logit - c_logit) > tol:
                mismatches += 1
                if len(mismatch_details) < 20:
                    mismatch_details.append(
                        {
                            "index": py_idx,
                            "python_pred": py_pred,
                            "c_pred": c_pred,
                            "python_logit": py_logit,
                            "c_logit": c_logit,
                            "label": py_label,
                        }
                    )

    print(f"\n{'='*60}")
    print(f"Comparison Results:")
    print(f"{'='*60}")
    print(f"Total samples compared: {total}")
    print(f"Matching predictions (and logits within tol):   {total - mismatches}")
    print(f"Mismatching predictions/logits: {mismatches}")
    print(f"Match rate:             {(total - mismatches) / total * 100:.2f}%")

    if mismatches > 0:
        print(f"\n{'='*60}")
        print(f"Mismatch Details (showing up to 20):")
        print(f"{'='*60}")
        print(
            f"{'Index':<8} {'Python':<8} {'C':<8} {'PyLogit':<12} {'CLogit':<12} {'Label':<6}"
        )
        print(f"{'-'*60}")
        for detail in mismatch_details:
            print(
                f"{detail['index']:<8} {detail['python_pred']:<8} {detail['c_pred']:<8} "
                f"{detail['python_logit']:<12.6f} {detail['c_logit']:<12.6f} {detail['label']:<6}"
            )

        print(f"\nERROR: Predictions/logits do not match within tolerance ({tol})!")
        sys.exit(1)
    else:
        print(
            f"\nSUCCESS: All predictions and top-logits match within tolerance ({tol})!"
        )
        print(
            f"Python ONNX Runtime and C ONNX Runtime produce identical numeric results."
        )


def main():
    python_csv = "python_predictions.csv"
    c_csv = "c_predictions.csv"

    if len(sys.argv) > 1:
        python_csv = sys.argv[1]
    if len(sys.argv) > 2:
        c_csv = sys.argv[2]

    try:
        compare_predictions(python_csv, c_csv)
    except FileNotFoundError as e:
        print(f"ERROR: File not found - {e}")
        print(f"\nUsage: python {sys.argv[0]} [python_csv] [c_csv]")
        print(f"Default: python {sys.argv[0]} python_predictions.csv c_predictions.csv")
        sys.exit(1)


if __name__ == "__main__":
    main()
